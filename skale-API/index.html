<!DOCTYPE html>
<!--[if lt IE 7 ]><html class="no-js ie6"><![endif]-->
<!--[if IE 7 ]><html class="no-js ie7"><![endif]-->
<!--[if IE 8 ]><html class="no-js ie8"><![endif]-->
<!--[if IE 9 ]><html class="no-js ie9"><![endif]-->
<!--[if (gt IE 9)|!(IE)]><!--> <html class="no-js"> <!--<![endif]-->
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,user-scalable=no,initial-scale=1,maximum-scale=1">
    
      
        <title>skale API - Skale</title>
      
      
      
      
    
    <meta property="og:url" content="None">
    <meta property="og:title" content="Skale">
    <meta property="og:image" content="None/../images/logo.svg">
    <meta name="apple-mobile-web-app-title" content="Skale">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    
      <link rel="apple-touch-icon" href="../images/logo.svg">
    
    
    <link rel="shortcut icon" type="image/x-icon" href="../assets/images/favicon-e565ddfa3b.ico">
    <link rel="icon" type="image/x-icon" href="../assets/images/favicon-e565ddfa3b.ico">
    <style>
      @font-face {
      	font-family: 'Icon';
      	src: url('../assets/fonts/icon.eot?52m981');
      	src: url('../assets/fonts/icon.eot?#iefix52m981')
               format('embedded-opentype'),
      		   url('../assets/fonts/icon.woff?52m981')
               format('woff'),
      		   url('../assets/fonts/icon.ttf?52m981')
               format('truetype'),
      		   url('../assets/fonts/icon.svg?52m981#icon')
               format('svg');
      	font-weight: normal;
      	font-style: normal;
      }
    </style>
    <link rel="stylesheet" href="../assets/stylesheets/application-a422ff04cc.css">
    
      <link rel="stylesheet" href="../assets/stylesheets/palettes-05ab2406df.css">
    
    
      
      
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,700|Ubuntu+Mono">
      <style>
        body, input {
          font-family: 'Ubuntu', Helvetica, Arial, sans-serif;
        }
        pre, code {
          font-family: 'Ubuntu Mono', 'Courier New', 'Courier', monospace;
        }
      </style>
    
    
    <script src="../assets/javascripts/modernizr-4ab42b99fd.js"></script>
    
  </head>
  
  
  
  <body class="palette-primary-indigo palette-accent-light-blue">
    
      
      
    
    <div class="backdrop">
      <div class="backdrop-paper"></div>
    </div>
    <input class="toggle" type="checkbox" id="toggle-drawer">
    <input class="toggle" type="checkbox" id="toggle-search">
    <label class="toggle-button overlay" for="toggle-drawer"></label>
    <header class="header">
      <nav aria-label="Header">
  <div class="bar default">
    <div class="button button-menu" role="button" aria-label="Menu">
      <label class="toggle-button icon icon-menu" for="toggle-drawer">
        <span></span>
      </label>
    </div>
    <div class="stretch">
      <div class="title">
        
          <span class="path">
            
          </span>
        
        skale API
      </div>
    </div>
    
    
    <div class="button button-search" role="button" aria-label="Search">
      <label class="toggle-button icon icon-search" title="Search" for="toggle-search"></label>
    </div>
  </div>
  <div class="bar search">
    <div class="button button-close" role="button" aria-label="Close">
      <label class="toggle-button icon icon-back" for="toggle-search"></label>
    </div>
    <div class="stretch">
      <div class="field">
        <input class="query" type="text" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck>
      </div>
    </div>
    <div class="button button-reset" role="button" aria-label="Search">
      <button class="toggle-button icon icon-close" id="reset-search"></button>
    </div>
  </div>
</nav>
    </header>
    <main class="main">
      
      <div class="drawer">
        <nav aria-label="Navigation">
  
  <a href="https://github.com/skale-me/skale-engine" class="project">
    <div class="banner">
      
        <div class="logo">
          <img src="../images/logo.svg">
        </div>
      
      <div class="name">
        <strong>
          Skale
          <span class="version">
            
          </span>
        </strong>
        
          <br>
          skale-me/skale-engine
        
      </div>
    </div>
  </a>
  <div class="scrollable">
    <div class="wrapper">
      
        <ul class="repo">
          <li class="repo-download">
            
            <a href="https://github.com/skale-me/skale-engine/archive/master.zip" target="_blank" title="Download" data-action="download">
              <i class="icon icon-download"></i> Download
            </a>
          </li>
          <li class="repo-stars">
            <a href="https://github.com/skale-me/skale-engine/stargazers" target="_blank" title="Stargazers" data-action="star">
              <i class="icon icon-star"></i> Stars
              <span class="count">&ndash;</span>
            </a>
          </li>
        </ul>
        <hr>
      
      <div class="toc">
        <ul>
          
            
  <li>
    <a class="" title="Home" href="..">
      Home
    </a>
    
  </li>

          
            
  <li>
    <a class="current" title="skale API" href="./">
      skale API
    </a>
    
      
        
      
      
        <ul>
          
            <li class="anchor">
              <a title="Overview" href="#overview">
                Overview
              </a>
            </li>
          
            <li class="anchor">
              <a title="Core concepts" href="#core-concepts">
                Core concepts
              </a>
            </li>
          
            <li class="anchor">
              <a title="Working with datasets" href="#working-with-datasets">
                Working with datasets
              </a>
            </li>
          
            <li class="anchor">
              <a title="Skale module" href="#skale-module">
                Skale module
              </a>
            </li>
          
            <li class="anchor">
              <a title="Machine Learning module" href="#machine-learning-module">
                Machine Learning module
              </a>
            </li>
          
        </ul>
      
    
  </li>

          
            
  <li>
    <a class="" title="Skale hackers guide" href="../skale-hackers-guide/">
      Skale hackers guide
    </a>
    
  </li>

          
        </ul>
        
      </div>
    </div>
  </div>
</nav>
      </div>
      <article class="article">
        <div class="wrapper">
          
          <h1 id="skale-reference">Skale Reference<a class="headerlink" href="#skale-reference" title="Permanent link">&para;</a></h1>
<h2 id="overview">Overview<a class="headerlink" href="#overview" title="Permanent link">&para;</a></h2>
<p>Skale is a fast and general purpose distributed data processing
system. It provides a high-level API in Javascript and an optimized
parallel execution engine.</p>
<p>A Skale application consists of a <em>master</em> program that runs the
user code and executes various <em>parallel operations</em> on a cluster
of <em>workers</em>.</p>
<p>The main abstraction Skale provides is a <em>dataset</em> which is similar
to a Javascript <em>array</em>, but partitioned accross the workers that
can be operated in parallel.</p>
<p>There are several ways to create a dataset: <em>parallelizing</em> an existing
array in the master program, or referencing a dataset in a distributed
storage system (such as HDFS), or <em>streaming</em> the content of any
source that can be processed through Node.js <em>Streams</em>. We call
<em>source</em> a function which initializes a dataset.</p>
<p>Datasets support two kinds of operations: <em>transformations</em>, which create
a new dataset from an existing one, and <em>actions</em>, which
return a value to the <em>master</em> program after running a computation
on the dataset.</p>
<p>For example, <code>map</code> is a transformation that applies a function to
each element of a dataset, returning a new dataset. On the other
hand, <code>reduce</code> is an action that aggregates all elements of a dataset
using some function, and returns the final result to the master.</p>
<p><em>Sources</em> and <em>transformations</em> in Skale are <em>lazy</em>. They do not
start right away, but are triggered by <em>actions</em>, thus allowing
efficient pipelined execution and optimized data transfers.</p>
<p>A first example:</p>
<pre class="codehilite"><code class="language-javascript">var sc = require('skale-engine').context();     // create a new context
sc.parallelize([1, 2, 3, 4]).               // source
   map(function (x) {return x+1}).          // transform
   reduce(function (a, b) {return a+b}, 0). // action
   then(console.log);                       // process result: 14</code></pre>


<h2 id="core-concepts">Core concepts<a class="headerlink" href="#core-concepts" title="Permanent link">&para;</a></h2>
<p>As stated above, a program can be considered as a workflow of steps,
each step consisting of a transformation which inputs from one or
more datasets (parents), and outputs to a new dataset (child).</p>
<h3 id="partitioning">Partitioning<a class="headerlink" href="#partitioning" title="Permanent link">&para;</a></h3>
<p>Datasets are divided into several partitions, so each partition can
be assigned to a separate worker, and processing can occur concurently
in a distributed and parallel system.</p>
<p>The consequence of this partitioning is that two types of transformations
exist:</p>
<ul>
<li>
<p><em>Narrow</em> transformations, where each partition of the parent dataset
  is used by at most one partition of the child dataset. This is the
  case for example for <code>map()</code> or <code>filter()</code>, where each dataset entry
  is processed independently from each other.
  Partitions are decoupled, no synchronization
  between workers is required, and narrow transformations can be
  pipelined on each worker.</p>
</li>
<li>
<p><em>Wide</em> transformations, where multiple child partitions may depend
  on one parent partition. This is the case for example for <code>sortBy()</code>
  or <code>groupByKey()</code>. Data need to be exchanged between workers or
  <em>shuffled</em>, in order to complete the transformation. This introduces
  synchronization points which prevent pipelining.</p>
</li>
</ul>
<h3 id="pipeline-stages-and-shuffles">Pipeline stages and shuffles<a class="headerlink" href="#pipeline-stages-and-shuffles" title="Permanent link">&para;</a></h3>
<p>Internally, each wide transformation consists of a pre-shuffle and
a post-shuffle part. All sequences of steps from source to pre-shuffle,
or from post-shuffle to next pre-shuffle or action, are thus only
narrow transformations, or pipelined stages (the most efficient
pattern).  A skale program is therefore simply a sequence of stages
and shuffles, shuffles being global serialization points.</p>
<p>It's important to grab this concept as it sets the limit to the
level of parallelism which can be achieved by a given code.</p>
<p>The synoptic table of <a href="#transformations">transformations</a> indicates
for each transformation if it is narrow or wide (shuffle).</p>
<h2 id="working-with-datasets">Working with datasets<a class="headerlink" href="#working-with-datasets" title="Permanent link">&para;</a></h2>
<h3 id="sources">Sources<a class="headerlink" href="#sources" title="Permanent link">&para;</a></h3>
<p>After having initialized a cluster context using
<a href="#skale-context">skale.context()</a>, one can create a dataset
using the following sources:</p>
<table>
<thead>
<tr>
<th>Source Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#sclinestreaminput_stream">lineStream(stream)</a></td>
<td>Create a dataset from a text stream</td>
</tr>
<tr>
<td><a href="#scobjectstreaminput_stream">objectStream(stream)</a></td>
<td>Create a dataset from an object stream</td>
</tr>
<tr>
<td><a href="#scparallelizearray">parallelize(array)</a></td>
<td>Create a dataset from an array</td>
</tr>
<tr>
<td><a href="#scrangestart-end-step">range(start,end,step)</a></td>
<td>Create a dataset containing integers from start to end</td>
</tr>
<tr>
<td><a href="#scsourcesize-callback-args">source(size,callback,args)</a></td>
<td>Create a dataset from a custom source function</td>
</tr>
<tr>
<td><a href="#sctextfilepath-options">textFile(path[, options])</a></td>
<td>Create a dataset from text file</td>
</tr>
</tbody>
</table>
<h3 id="transformations">Transformations<a class="headerlink" href="#transformations" title="Permanent link">&para;</a></h3>
<p>Transformations operate on a dataset and return a new dataset. Note that some
transformation operate only on datasets where each element is in the form
of 2 elements array of key and value (<code>[k,v]</code> dataset):</p>
<pre class="codehilite"><code>[[Ki,Vi], ..., [Kj, Vj]]</code></pre>


<p>A special transformation <code>persist()</code> enables one to <em>persist</em> a dataset
in memory, allowing efficient reuse accross parallel operations.</p>
<table>
<thead>
<tr>
<th>Transformation Name</th>
<th>Description</th>
<th>In</th>
<th>Out</th>
<th>Shuffle</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#dsaggregatebykeyreducer-combiner-init-obj">aggregateByKey(func, func, init)</a></td>
<td>reduce and combine by key using functions</td>
<td>[k,v]</td>
<td>[k,v]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dscartesianother">cartesian(other)</a></td>
<td>Perform a cartesian product with the other dataset</td>
<td>v w</td>
<td>[v,w]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dscogroupother">coGroup(other)</a></td>
<td>Group data from both datasets sharing the same key</td>
<td>[k,v] [k,w]</td>
<td>[k,[[v],[w]]]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dsdistinct">distinct()</a></td>
<td>Return a dataset where duplicates are removed</td>
<td>v</td>
<td>w</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dsfilterfilter-obj">filter(func)</a></td>
<td>Return a dataset of elements on which function returns true</td>
<td>v</td>
<td>w</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dsflatmapflatmapper-obj">flatMap(func)</a></td>
<td>Pass the dataset elements to a function which returns a sequence</td>
<td>v</td>
<td>w</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dsflatmapflatvaluesmapper-obj">flatMapValues(func)</a></td>
<td>Pass the dataset [k,v] elements to a function without changing the keys</td>
<td>[k,v]</td>
<td>[k,w]</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dsgroupbykey">groupByKey()</a></td>
<td>Group values with the same key</td>
<td>[k,v]</td>
<td>[k,[v]]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dsintersectionother">intersection(other)</a></td>
<td>Return a dataset containing only elements found in both datasets</td>
<td>v w</td>
<td>v</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dsjoinother">join(other)</a></td>
<td>Perform an inner join between 2 datasets</td>
<td>[k,v]</td>
<td>[k,[v,w]]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dsleftouterjoinother">leftOuterJoin(other)</a></td>
<td>Join 2 datasets where the key must be present in the other</td>
<td>[k,v]</td>
<td>[k,[v,w]]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dsrightouterjoinother">rightOuterJoin(other)</a></td>
<td>Join 2 datasets where the key must be present in the first</td>
<td>[k,v]</td>
<td>[k,[v,w]]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dskeys">keys()</a></td>
<td>Return a dataset of just the keys</td>
<td>[k,v]</td>
<td>k</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dsmapmapper-obj">map(func)</a></td>
<td>Return a dataset where elements are passed through a function</td>
<td>v</td>
<td>w</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dsmapvaluesmapper-obj">mapValues(func)</a></td>
<td>Map a function to the value field of key-value dataset</td>
<td>[k,v]</td>
<td>[k,w]</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dsreducebykeyreducer-init-obj">reduceByKey(func, init)</a></td>
<td>Combine values with the same key</td>
<td>[k,v]</td>
<td>[k,w]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dspartitionbypartitioner">partitionBy(partitioner)</a></td>
<td>Partition using the partitioner</td>
<td>v</td>
<td>v</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dspersist">persist()</a></td>
<td>Idempotent. Keep content of dataset in cache for further reuse.</td>
<td>v</td>
<td>v</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dssamplewithreplacement-frac-seed">sample(rep, frac, seed)</a></td>
<td>Sample a dataset, with or without replacement</td>
<td>v</td>
<td>w</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dssortbykeyfunc-ascending">sortBy(func)</a></td>
<td>Sort a dataset</td>
<td>v</td>
<td>v</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dssortbykeyascending">sortByKey()</a></td>
<td>Sort a [k,v] dataset</td>
<td>[k,v]</td>
<td>[k,v]</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dssubtractother">subtract(other)</a></td>
<td>Remove the content of one dataset</td>
<td>v w</td>
<td>v</td>
<td>yes</td>
</tr>
<tr>
<td><a href="#dsunionother">union(other)</a></td>
<td>Return a dataset containing elements from both datasets</td>
<td>v</td>
<td>v w</td>
<td>no</td>
</tr>
<tr>
<td><a href="#dsvalues">values()</a></td>
<td>Return a dataset of just the values</td>
<td>[k,v]</td>
<td>v</td>
<td>no</td>
</tr>
</tbody>
</table>
<h3 id="actions">Actions<a class="headerlink" href="#actions" title="Permanent link">&para;</a></h3>
<p>Actions operate on a dataset and send back results to the <em>master</em>. Results
are always produced asynchronously and send to an optional callback function,
alternatively through a returned <a href="https://promisesaplus.com">ES6 promise</a>.</p>
<table>
<thead>
<tr>
<th>Action Name</th>
<th>Description</th>
<th>out</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="#dsaggregatereducer-combiner-init-obj-done">aggregate(func, func, init)</a></td>
<td>Similar to reduce() but may return a different type</td>
<td>value</td>
</tr>
<tr>
<td><a href="#dscollectdone">collect()</a></td>
<td>Return the content of dataset</td>
<td>array of elements</td>
</tr>
<tr>
<td><a href="#dscountdone">count()</a></td>
<td>Return the number of elements from dataset</td>
<td>number</td>
</tr>
<tr>
<td><a href="#dscountbykeydone">countByKey()</a></td>
<td>Return the number of occurrences for each key in a <code>[k,v]</code> dataset</td>
<td>array of [k,number]</td>
</tr>
<tr>
<td><a href="#dscountbyvaluedone">countByValue()</a></td>
<td>Return the number of occurrences of elements from dataset</td>
<td>array of [v,number]</td>
</tr>
<tr>
<td><a href="#dsfirstdone">first()</a></td>
<td>Return the first element in dataset</td>
<td>value</td>
</tr>
<tr>
<td><a href="#dsforeachcallback-obj-done">forEach(func)</a></td>
<td>Apply the provided function to each element of the dataset</td>
<td>empty</td>
</tr>
<tr>
<td><a href="#dslookupk-done">lookup(k)</a></td>
<td>Return the list of values <code>v</code> for key <code>k</code> in a <code>[k,v]</code> dataset</td>
<td>array of v</td>
</tr>
<tr>
<td><a href="#dsreducereducer-init-obj-done">reduce(func, init)</a></td>
<td>Aggregates dataset elements using a function into one value</td>
<td>value</td>
</tr>
<tr>
<td><a href="#dssaveurl-options-done">save(url)</a></td>
<td>Save the content of a dataset to an url</td>
<td>empty</td>
</tr>
<tr>
<td><a href="#dsstream-opt">stream()</a></td>
<td>Stream out a dataset</td>
<td>stream</td>
</tr>
<tr>
<td><a href="#dstakenum-done">take(num)</a></td>
<td>Return the first <code>num</code> elements of dataset</td>
<td>array of value</td>
</tr>
<tr>
<td><a href="#dstakesamplewithreplacement-num-done">takeSample(withReplacement, num)</a></td>
<td>Return a sample of <code>num</code> elements of dataset</td>
<td>array of value</td>
</tr>
<tr>
<td><a href="#dstopnum-done">top(num)</a></td>
<td>Return the top <code>num</code> elements of dataset</td>
<td>array of value</td>
</tr>
</tbody>
</table>
<h2 id="skale-module">Skale module<a class="headerlink" href="#skale-module" title="Permanent link">&para;</a></h2>
<p>The Skale module is the main entry point for Skale functionality.
To use it, one must <code>require('skale-engine')</code>.</p>
<h3 id="skalecontextconfig">skale.context([config])<a class="headerlink" href="#skalecontextconfig" title="Permanent link">&para;</a></h3>
<p>Creates and returns a new context which represents the connection
to the Skale cluster, and which can be used to create datasets on that
cluster. Config is an <em>Object</em> which defines the cluster server,
with the following defaults:</p>
<pre class="codehilite"><code class="language-javascript">{
  host: 'localhost',    // Cluster server host, settable also by SKALE_HOST env
  port: '12346'         // Cluster server port, settable also by SKALE_PORT env
}</code></pre>


<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var skale = require('skale-engine');
var sc = skale.context();</code></pre>


<h4 id="scenv">sc.env<a class="headerlink" href="#scenv" title="Permanent link">&para;</a></h4>
<p>The <code>sc.env</code> property returns an object containing user environment variables
to be set in workers.</p>
<p>To set and propagate an environment variable to all workers, assign <code>sc.env</code> object
prior to invoking an action.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.env.MY_VAR = 'my_value';</code></pre>


<h4 id="scend">sc.end()<a class="headerlink" href="#scend" title="Permanent link">&para;</a></h4>
<p>Closes the connection to the cluster.</p>
<h4 id="sclinestreaminput_stream">sc.lineStream(input_stream)<a class="headerlink" href="#sclinestreaminput_stream" title="Permanent link">&para;</a></h4>
<p>Returns a new dataset of lines of text read from input_stream
<em>Object</em>, which is a <a href="https://nodejs.org/api/stream.html#stream_class_stream_readable">readable stream</a> where dataset content is
read from.</p>
<p>The following example computes the size of a file using streams:</p>
<pre class="codehilite"><code class="language-javascript">var stream = fs.createReadStream('data.txt', 'utf8');
sc.lineStream(stream).
   map(s =&gt; s.length).
   reduce((a, b) =&gt; a + b, 0).
   then(console.log);</code></pre>


<h4 id="scobjectstreaminput_stream">sc.objectStream(input_stream)<a class="headerlink" href="#scobjectstreaminput_stream" title="Permanent link">&para;</a></h4>
<p>Returns a new dataset of Javascript <em>Objects</em> read from input_stream
<em>Object</em>, which is a <a href="https://nodejs.org/api/stream.html#stream_class_stream_readable">readable stream</a> where dataset content is
read from.</p>
<p>The following example counts the number of objects returned in an
object stream using the mongodb native Javascript driver:</p>
<pre class="codehilite"><code class="language-javascript">var cursor = db.collection('clients').find();
sc.objectStream(cursor).count().then(console.log);</code></pre>


<h4 id="scparallelizearray">sc.parallelize(array)<a class="headerlink" href="#scparallelizearray" title="Permanent link">&para;</a></h4>
<p>Returns a new dataset containing elements from the <em>Array</em> array.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var a = sc.parallelize(['Hello', 'World']);</code></pre>


<h4 id="scrangestart-end-step">sc.range(start[, end[, step]])<a class="headerlink" href="#scrangestart-end-step" title="Permanent link">&para;</a></h4>
<p>Returns a new dataset of integers from <em>start</em> to <em>end</em> (exclusive)
increased by <em>step</em> (default 1) every element. If called with a
single argument, the argument is interpreted as <em>end</em>, and <em>start</em>
is set to 0.</p>
<pre class="codehilite"><code class="language-javascript">sc.range(5).collect().then(console.log)
// [ 0, 1, 2, 3, 4 ]
sc.range(2, 4).collect().then(console.log)
// [ 2, 3 ]
sc.range(10, -5, -3).collect().then(console.log)
// [ 10, 7, 4, 1, -2 ]</code></pre>


<h4 id="scsourcesize-callback-args">sc.source(size, callback[, args])<a class="headerlink" href="#scsourcesize-callback-args" title="Permanent link">&para;</a></h4>
<p>Returns a new dataset of <em>size</em> elements, where each element is
generated by a custom function <em>callback</em> executed on workers.</p>
<ul>
<li><em>size</em>: an integer <em>Number</em> of elements in the dataset</li>
<li><em>callback</em>: a function of the form <code>function(index, args[, wc])</code>
  which returns the next element and with:<ul>
<li><em>index</em>: the index of the element in the dataset, comprised
  between <code>0</code> and <code>size - 1</code></li>
<li><em>args</em>: the same parameter <em>args</em> passed to source</li>
<li><em>wc</em>: the worker context, a persistent object local to each
  worker, where user can store and access worker local dependencies</li>
</ul>
</li>
<li><em>args</em>: user custom parameter, passed to <em>callback</em></li>
</ul>
<pre class="codehilite"><code class="language-javascript">function randArray(index, len) {
  var arr = [];
  for (var i = 0; i &lt; len; i++)
    arr.push(Math.floor(Math.random() * 100));
  return arr;
}

sc.source(3, randArray, 2).collect().then(console.log);
// [ [ 31, 85 ], [ 93, 21 ], [ 99, 58 ] ]</code></pre>


<h4 id="sctextfilepath-options">sc.textFile(path[, options])<a class="headerlink" href="#sctextfilepath-options" title="Permanent link">&para;</a></h4>
<p>Returns a new dataset of lines in file specified by path <em>String</em>.</p>
<ul>
<li><em>path</em>: a <em>String</em> of the general form <code>protocol://host/path</code> or <code>/path</code>,
  where protocol can be one of:</li>
<li><em>file</em>: if path is on local filesystem</li>
<li><em>s3</em>: if path relates to a repository on AWS [S3] storage system</li>
<li><em>wasb</em>: if path relates to a repository on Azure blob storage system</li>
<li><em>options</em>: an <em>Object</em> with the following fields:</li>
<li><em>maxFiles</em>: a <em>Number</em> of maximum files to process if the path refers
    to a directory.</li>
<li><em>parquet</em>: a <em>Boolean</em> to indicate that all files are in the
    <a href="https://parquet.apache.org">parquet</a> format. Default value is <em>false</em>.</li>
</ul>
<p>if <em>path</em> ends by a '/' (directory separator), then the dataset
will be composed of all the files in the directory. Sub-directories
are not supported. Wildcard characters such as <code>*</code>, <code>?</code>, etc, as
in the Unix Shell globbing patterns are supported.</p>
<p>If a file name ends by '.gz', then its content will be automatically
uncompressed using GZIP.</p>
<p>If a file name ends by '.parquet', it will automatically be processed
as a <a href="https://parquet.apache.org">parquet</a>.</p>
<p>Note: If using a path on the local filesystem, the file must also
be accessible at the same path on worker nodes. Either copy the
file to all workers or use a network-mounted shared file system.</p>
<p>For example, the following program prints the length of a text file:</p>
<pre class="codehilite"><code class="language-javascript">var lines = sc.textFile('data.txt');
lines.map(s =&gt; s.length).reduce((a, b) =&gt; a + b, 0).then(console.log);</code></pre>


<h3 id="dataset-methods">Dataset methods<a class="headerlink" href="#dataset-methods" title="Permanent link">&para;</a></h3>
<p>Dataset objects, as created initially by above skale context source
functions, have the following methods, allowing either to instantiate
a new dataset through a transformation, or to return results to the
master program.</p>
<h4 id="dsaggregatereducer-combiner-init-obj-done">ds.aggregate(reducer, combiner, init[, obj][, done])<a class="headerlink" href="#dsaggregatereducer-combiner-init-obj-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> computes the aggregated value of the elements
of the dataset using two functions <em>reducer()</em> and <em>combiner()</em>,
allowing to use an arbitrary accumulator type, different from element
type (as opposed to <code>reduce()</code> which imposes the same type for
accumulator and element).
The result is passed to the <em>done()</em> callback if provided, otherwise an
<a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>reducer</em>: a function of the form <code>function(acc, val[, obj[, wc]])</code>,
  which returns the next value of the accumulator (which must be
  of the same type as <em>acc</em>) and with:<ul>
<li><em>acc</em>: the value of the accumulator, initially set to <em>init</em></li>
<li><em>val</em>: the value of the next element of the dataset on which
   <code>aggregate()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>aggregate()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
   worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>combiner</em>: a function of the form <code>function(acc1, acc2[, obj])</code>,
  which returns the merged value of accumulators and with:<ul>
<li><em>acc1</em>: the value of an accumulator, computed locally on a worker</li>
<li><em>acc2</em>: the value of an other accumulator, issued by another worker</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>aggregate()</code></li>
</ul>
</li>
<li><em>init</em>: the initial value of the accumulators that are used by
  <em>reducer()</em> and <em>combiner()</em>. It should be the identity element
  of the operation (a neutral zero value, i.e. applying it through the
  function should not change result).</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset.</li>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion. If <em>undefined</em>, <code>aggregate()</code> returns an
  <a href="https://promisesaplus.com">ES6 promise</a>.</li>
</ul>
<p>The following example computes the average of a dataset, avoiding a <code>map()</code>:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([3, 5, 2, 7, 4, 8]).
   aggregate((a, v) =&gt; [a[0] + v, a[1] + 1],
    (a1, a2) =&gt; [a1[0] + a2[0], a1[1] + a2[1]], [0, 0]).
   then(function(data) {
    console.log(data[0] / data[1]);
  })
// 4.8333</code></pre>


<h4 id="dsaggregatebykeyreducer-combiner-init-obj">ds.aggregateByKey(reducer, combiner, init,[ obj])<a class="headerlink" href="#dsaggregatebykeyreducer-combiner-init-obj" title="Permanent link">&para;</a></h4>
<p>When called on a dataset of type <code>[k,v]</code>, returns a dataset of type
<code>[k,v]</code> where <code>v</code> is the aggregated value of all elements of same
key <code>k</code>. The aggregation is performed using two functions <em>reducer()</em>
and <em>combiner()</em> allowing to use an arbitrary accumulator type,
different from element type.</p>
<ul>
<li><em>reducer</em>: a function of the form <code>function(acc, val[, obj[, wc]])</code>,
  which returns the next value of the accumulator (which must be
  of the same type as <em>acc</em>) and with:<ul>
<li><em>acc</em>: the value of the accumulator, initially set to <em>init</em></li>
<li><em>val</em>: the value <code>v</code> of the next <code>[k,v]</code> element of the dataset
   on which <code>aggregateByKey()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>aggregateByKey()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
   worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>combiner</em>: a function of the form <code>function(acc1, acc2[, obj])</code>,
  which returns the merged value of accumulators and with:<ul>
<li><em>acc1</em>: the value of an accumulator, computed locally on a worker</li>
<li><em>acc2</em>: the value of an other accumulator, issued by another worker</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>aggregate()</code></li>
</ul>
</li>
<li><em>init</em>: the initial value of the accumulators that are used by
  <em>reducer()</em> and <em>combiner()</em>. It should be the identity element
  of the operation (a neutral zero value, i.e. applying it through the
  function should not change result).</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([['hello', 1], ['hello', 1], ['world', 1]]).
   aggregateByKey((a, b) =&gt; a + b, (a, b) =&gt; a + b, 0).
   collect().then(console.log);
// [ [ 'hello', 2 ], [ 'world', 1 ] ]</code></pre>


<h4 id="dscartesianother">ds.cartesian(other)<a class="headerlink" href="#dscartesianother" title="Permanent link">&para;</a></h4>
<p>Returns a dataset wich contains all possible pairs <code>[a, b]</code> where <code>a</code>
is in the source dataset and <code>b</code> is in the <em>other</em> dataset.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([1, 2]);
var ds2 = sc.parallelize(['a', 'b', 'c']);
ds1.cartesian(ds2).collect().then(console.log);
// [ [ 1, 'a' ], [ 1, 'b' ], [ 1, 'c' ],
//   [ 2, 'a' ], [ 2, 'b' ], [ 2, 'c' ] ]</code></pre>


<h4 id="dscogroupother">ds.coGroup(other)<a class="headerlink" href="#dscogroupother" title="Permanent link">&para;</a></h4>
<p>When called on dataset of type <code>[k,v]</code> and <code>[k,w]</code>, returns a dataset of type
<code>[k, [[v], [w]]]</code>, where data of both datasets share the same key.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([[10, 1], [20, 2]]);
var ds2 = sc.parallelize([[10, 'world'], [30, 3]]);
ds1.coGroup(ds2).collect().then(console.log);
// [ [ 10, [ [ 1 ], [ 'world' ] ] ],
//   [ 20, [ [ 2 ], [] ] ],
//   [ 30, [ [], [ 3 ] ] ] ]</code></pre>


<h4 id="dscollectdone">ds.collect([done])<a class="headerlink" href="#dscollectdone" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> returns the content of the dataset in form of an array.
The result is passed to the <em>done()</em> callback if provided, otherwise an
<a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([1, 2, 3, 4]).
   collect(function (err, res) {
     console.log(res);
   });
// [ 1, 2, 3, 4 ]</code></pre>


<h4 id="dscountdone">ds.count([done])<a class="headerlink" href="#dscountdone" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> computes the number of elements in the dataset. The
result is passed to the <em>done()</em> callback if provided, otherwise
an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([10, 20, 30, 40]).count().then(console.log);
// 4</code></pre>


<h4 id="dscountbykeydone">ds.countByKey([done])<a class="headerlink" href="#dscountbykeydone" title="Permanent link">&para;</a></h4>
<p>When called on a dataset of type <code>[k,v]</code>, this <a href="#actions">action</a> computes
the number of occurrences of elements for each key in a dataset of
type <code>[k,v]</code>. It produces an array of elements of type <code>[k,w]</code> where
<code>w</code> is the result count.  The result is passed to the <em>done()</em>
callback if provided, otherwise an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([[10, 1], [20, 2], [10, 4]]).
   countByKey().then(console.log);
// [ [ 10, 2 ], [ 20, 1 ] ]</code></pre>


<h4 id="dscountbyvaluedone">ds.countByValue([done])<a class="headerlink" href="#dscountbyvaluedone" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> computes the number of occurences of each element in
dataset and returns an array of elements of type <code>[v,n]</code> where <code>v</code>
is the element and <code>n</code> its number of occurrences.  The result is
passed to the <em>done()</em> callback if provided, otherwise an <a href="https://promisesaplus.com">ES6
promise</a> is returned.</p>
<ul>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([ 1, 2, 3, 1, 3, 2, 5 ]).
   countByValue().then(console.log);
// [ [ 1, 2 ], [ 2, 2 ], [ 3, 2 ], [ 5, 1 ] ]</code></pre>


<h4 id="dsdistinct">ds.distinct()<a class="headerlink" href="#dsdistinct" title="Permanent link">&para;</a></h4>
<p>Returns a dataset where duplicates are removed.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([ 1, 2, 3, 1, 4, 3, 5 ]).
   distinct().
   collect().then(console.log);
// [ 1, 2, 3, 4, 5 ]</code></pre>


<h4 id="dsfilterfilter-obj">ds.filter(filter[, obj])<a class="headerlink" href="#dsfilterfilter-obj" title="Permanent link">&para;</a></h4>
<ul>
<li><em>filter</em>: a function of the form <code>callback(element[, obj[, wc]])</code>,
  returning a <em>Boolean</em> and where:<ul>
<li><em>element</em>: the next element of the dataset on which <code>filter()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>filter()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
  worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
</ul>
<p>Applies the provided filter function to each element of the source
dataset and returns a new dataset containing the elements that passed the
test.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">function filter(data, obj) { return data % obj.modulo; }

sc.parallelize([1, 2, 3, 4]).
   filter(filter, {modulo: 2}).
   collect().then(console.log);
// [ 1, 3 ]</code></pre>


<h4 id="dsfirstdone">ds.first([done])<a class="headerlink" href="#dsfirstdone" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> computes the first element in this dataset.
The result is passed to the <em>done()</em> callback if provided, otherwise an
<a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([1, 2, 3]).first().then(console.log);
// 1</code></pre>


<h4 id="dsflatmapflatmapper-obj">ds.flatMap(flatMapper[, obj])<a class="headerlink" href="#dsflatmapflatmapper-obj" title="Permanent link">&para;</a></h4>
<p>Applies the provided mapper function to each element of the source
dataset and returns a new dataset.</p>
<ul>
<li><em>flatMapper</em>: a function of the form <code>callback(element[, obj[, wc]])</code>,
  returning an <em>Array</em> and where:<ul>
<li><em>element</em>: the next element of the dataset on which <code>flatMap()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>flatMap()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
  worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.range(5).flatMap(a =&gt; [a, a]).collect().then(console.log);
// [ 0, 0, 1, 1, 2, 2, 3, 3, 4, 4 ]</code></pre>


<h4 id="dsflatmapvaluesflatmapper-obj">ds.flatMapValues(flatMapper[, obj])<a class="headerlink" href="#dsflatmapvaluesflatmapper-obj" title="Permanent link">&para;</a></h4>
<p>Applies the provided flatMapper function to the value of each [key,
value] element of the source dataset and return a new dataset containing
elements defined as [key, mapper(value)], keeping the key unchanged
for each source element.</p>
<ul>
<li><em>flatMapper</em>: a function of the form <code>callback(element[, obj[, wc]])</code>,
  returning an <em>Array</em> and where:<ul>
<li><em>element</em>: the value v of the next [k,v] element of the dataset on
  which <code>flatMapValues()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>flatMapValues()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
  worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">function valueFlatMapper(data, obj) {
    var tmp = [];
    for (var i = 0; i &lt; obj.N; i++) tmp.push(data * obj.fact);
    return tmp;
}

sc.parallelize([['hello', 1], ['world', 2]]).
   flatMapValues(valueFlatMapper, {N: 2, fact: 2}).
   collect().then(console.log);
// [ [ 'hello', 2 ], [ 'hello', 2 ], [ 'world', 4 ], [ 'world', 4 ] ]</code></pre>


<h4 id="dsforeachcallback-obj-done">ds.forEach(callback[, obj][, done])<a class="headerlink" href="#dsforeachcallback-obj-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> applies a <em>callback</em> function on each element of the dataset.
If provided, the <em>done()</em> callback is invoked at completion, otherwise an
<a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>callback</em>: a function of the form <code>function(val[, obj[, wc]])</code>,
  which returns <em>null</em> and with:<ul>
<li><em>val</em>: the value of the next element of the dataset on which
   <code>forEach()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>forEach()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
   worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>In the following example, the <code>console.log()</code> callback provided
to <code>forEach()</code> is executed on workers and may be not visible:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([1, 2, 3, 4]).
   forEach(console.log).then(console.log('finished'));</code></pre>


<h4 id="dsgroupbykey">ds.groupByKey()<a class="headerlink" href="#dsgroupbykey" title="Permanent link">&para;</a></h4>
<p>When called on a dataset of type <code>[k,v]</code>, returns a dataset of type <code>[k, [v]]</code>
where values with the same key are grouped.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([[10, 1], [20, 2], [10, 4]]).
   groupByKey().collect().then(console.log);
// [ [ 10, [ 1, 4 ] ], [ 20, [ 2 ] ] ]</code></pre>


<h4 id="dsintersectionother">ds.intersection(other)<a class="headerlink" href="#dsintersectionother" title="Permanent link">&para;</a></h4>
<p>Returns a dataset containing only elements found in source dataset and <em>other</em>
dataset.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([1, 2, 3, 4, 5]);
var ds2 = sc.parallelize([3, 4, 5, 6, 7]);
ds1.intersection(ds2).collect().then(console.log); // [ 3, 4, 5 ]</code></pre>


<h4 id="dsjoinother">ds.join(other)<a class="headerlink" href="#dsjoinother" title="Permanent link">&para;</a></h4>
<p>When called on source dataset of type <code>[k,v]</code> and <em>other</em> dataset of type
<code>[k,w]</code>, returns a dataset of type <code>[k, [v, w]]</code> pairs with all pairs
of elements for each key.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([[10, 1], [20, 2]]);
var ds2 = sc.parallelize([[10, 'world'], [30, 3]]);
ds1.join(ds2).collect().then(console.log);
// [ [ 10, [ 1, 'world' ] ] ]</code></pre>


<h4 id="dskeys">ds.keys()<a class="headerlink" href="#dskeys" title="Permanent link">&para;</a></h4>
<p>When called on source dataset of type <code>[k,v]</code>, returns a dataset with just
the elements <code>k</code>.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([[10, 'world'], [30, 3]]).
   keys.collect().then(console.log);
// [ 10, 30 ]</code></pre>


<h4 id="dsleftouterjoinother">ds.leftOuterJoin(other)<a class="headerlink" href="#dsleftouterjoinother" title="Permanent link">&para;</a></h4>
<p>When called on source dataset of type <code>[k,v]</code> and <em>other</em> dataset of type
<code>[k,w]</code>, returns a dataset of type <code>[k, [v, w]]</code> pairs where the key
must be present in the <em>other</em> dataset.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([[10, 1], [20, 2]]);
var ds2 = sc.parallelize([[10, 'world'], [30, 3]]);
ds1.leftOuterJoin(ds2).collect().then(console.log);
// [ [ 10, [ 1, 'world' ] ], [ 20, [ 2, null ] ] ]</code></pre>


<h4 id="dslookupk-done">ds.lookup(k[, done])<a class="headerlink" href="#dslookupk-done" title="Permanent link">&para;</a></h4>
<p>When called on source dataset of type <code>[k,v]</code>, returns an array
of values <code>v</code> for key <code>k</code>.
The result is passed to the <em>done()</em> callback if provided, otherwise an
<a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([[10, 'world'], [20, 2], [10, 1], [30, 3]]).
   lookup(10).then(console.log);
// [ world, 1 ]</code></pre>


<h4 id="dsmapmapper-obj">ds.map(mapper[, obj])<a class="headerlink" href="#dsmapmapper-obj" title="Permanent link">&para;</a></h4>
<p>Applies the provided mapper function to each element of the source
dataset and returns a new dataset.</p>
<ul>
<li><em>mapper</em>: a function of the form <code>callback(element[, obj[, wc]])</code>,
  returning an element and where:<ul>
<li><em>element</em>: the next element of the dataset on which <code>map()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>map()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
  worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([1, 2, 3, 4]).
   map((data, obj) =&gt; data * obj.scaling, {scaling: 1.2}).
   collect().then(console.log);
// [ 1.2, 2.4, 3.6, 4.8 ]</code></pre>


<h4 id="dsmapvaluesmapper-obj">ds.mapValues(mapper[, obj])<a class="headerlink" href="#dsmapvaluesmapper-obj" title="Permanent link">&para;</a></h4>
<ul>
<li><em>mapper</em>: a function of the form <code>callback(element[, obj[, wc]])</code>,
  returning an element and where:<ul>
<li><em>element</em>: the value v of the next [k,v] element of the dataset on
  which <code>mapValues()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>mapValues()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
  worker, where user can store and access worker local dependencies</li>
</ul>
</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
</ul>
<p>Applies the provided mapper function to the value of each <code>[k,v]</code>
element of the source dataset and return a new dataset containing elements
defined as <code>[k, mapper(v)]</code>, keeping the key unchanged for each
source element.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([['hello', 1], ['world', 2]]).
   mapValues((a, obj) =&gt; a*obj.fact, {fact: 2}).
   collect().then(console.log);
// [ ['hello', 2], ['world', 4] ]</code></pre>


<h4 id="dspartitionbypartitioner">ds.partitionBy(partitioner)<a class="headerlink" href="#dspartitionbypartitioner" title="Permanent link">&para;</a></h4>
<p>Returns a dataset partitioned using the specified partitioner. The
purpose of this transformation is not to change the dataset content,
but to increase processing speed by ensuring that the elements
accessed by further transfomations reside in the same partition.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var skale = require('skale-engine');
var sc = skale.context();

sc.parallelize([['hello', 1], ['world', 1], ['hello', 2], ['world', 2], ['cedric', 3]])
  .partitionBy(new skale.HashPartitioner(3))
  .collect.then(console.log)
// [ ['world', 1], ['world', 2], ['hello', 1], ['hello', 2], ['cedric', 3] ]</code></pre>


<h4 id="dspersist">ds.persist()<a class="headerlink" href="#dspersist" title="Permanent link">&para;</a></h4>
<p>Returns the dataset, and persists the dataset content on disk (and
in memory if available) in order to directly reuse content in further
tasks.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var dataset = sc.range(100).map(a =&gt; a * a);

// First action: compute dataset
dataset.collect().then(console.log)

// Second action: reuse dataset, avoid map transform
dataset.collect().then(console.log)</code></pre>


<h4 id="dsreducereducer-init-obj-done">ds.reduce(reducer, init[, obj][, done])<a class="headerlink" href="#dsreducereducer-init-obj-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> returns the aggregated value of the elements
of the dataset using a <em>reducer()</em> function.
The result is passed to the <em>done()</em> callback if provided, otherwise an
<a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>reducer</em>: a function of the form <code>function(acc, val[, obj[, wc]])</code>,
  which returns the next value of the accumulator (which must be
  of the same type as <em>acc</em> and <em>val</em>) and with:<ul>
<li><em>acc</em>: the value of the accumulator, initially set to <em>init</em></li>
<li><em>val</em>: the value of the next element of the dataset on which
   <code>reduce()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>reduce()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
   worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>init</em>: the initial value of the accumulators that are used by
  <em>reducer()</em>. It should be the identity element of the operation
  (i.e. applying it through the function should not change result).</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([1, 2, 4, 8]).
   reduce((a, b) =&gt; a + b, 0).
   then(console.log);
// 15</code></pre>


<h4 id="dsreducebykeyreducer-init-obj">ds.reduceByKey(reducer, init[, obj])<a class="headerlink" href="#dsreducebykeyreducer-init-obj" title="Permanent link">&para;</a></h4>
<ul>
<li><em>reducer</em>: a function of the form <code>callback(acc,val[, obj[, wc]])</code>,
  returning the next value of the accumulator (which must be of the
  same type as <em>acc</em> and <em>val</em>) and where:<ul>
<li><em>acc</em>: the value of the accumulator, initially set to <em>init</em></li>
<li><em>val</em>: the value <code>v</code> of the next <code>[k,v]</code> element of the dataset on
  which <code>reduceByKey()</code> operates</li>
<li><em>obj</em>: the same parameter <em>obj</em> passed to <code>reduceByKey()</code></li>
<li><em>wc</em>: the worker context, a persistent object local to each
  worker, where user can store and access worker local dependencies.</li>
</ul>
</li>
<li><em>init</em>: the initial value of accumulator for each key. Will be
  passed to <em>reducer</em>.</li>
<li><em>obj</em>: user provided data. Data will be passed to carrying
  serializable data from master to workers, obj is shared amongst
  mapper executions over each element of the dataset</li>
</ul>
<p>When called on a dataset of type <code>[k,v]</code>, returns a dataset of type <code>[k,v]</code>
where the values of each key are aggregated using the <em>reducer</em>
function and the <em>init</em> initial value.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([[10, 1], [10, 2], [10, 4]]).
   reduceByKey((a,b) =&gt; a+b, 0).
   collect().then(console.log);
// [ [10, 7] ]</code></pre>


<h4 id="dsrightouterjoinother">ds.rightOuterJoin(other)<a class="headerlink" href="#dsrightouterjoinother" title="Permanent link">&para;</a></h4>
<p>When called on source dataset of type <code>[k,v]</code> and <em>other</em> dataset of type
<code>[k,w]</code>, returns a dataset of type <code>[k, [v, w]]</code> pairs where the key
must be present in the <em>source</em> dataset.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([[10, 1], [20, 2]]);
var ds2 = sc.parallelize([[10, 'world'], [30, 3]]);
ds1.rightOuterJoin(ds2).collect().then(console.log);
// [ [ 10, [ 1, 'world' ] ], [ 30, [ null, 2 ] ] ]</code></pre>


<h4 id="dssamplewithreplacement-frac-seed">ds.sample(withReplacement, frac, seed)<a class="headerlink" href="#dssamplewithreplacement-frac-seed" title="Permanent link">&para;</a></h4>
<ul>
<li><em>withReplacement</em>: <em>Boolean</em> value, <em>true</em> if data must be sampled
  with replacement</li>
<li><em>frac</em>: <em>Number</em> value of the fraction of source dataset to return</li>
<li><em>seed</em>: <em>Number</em> value of pseudo-random seed</li>
</ul>
<p>Returns a dataset by sampling a fraction <em>frac</em> of source dataset, with or
without replacement, using a given random generator <em>seed</em>.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([1, 2, 3, 4, 5, 6, 7, 8]).
   sample(true, 0.5, 0).
   collect().then(console.log);
// [ 1, 1, 3, 4, 4, 5, 7 ]</code></pre>


<h4 id="dssaveurl-options-done">ds.save(url[, options][, done])<a class="headerlink" href="#dssaveurl-options-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> saves the content of the dataset to the destination URL. The
destination is a flat directory which will contain as many files as partitions
in the dataset. Files are named from partition numbers, starting at 0.
The file format is a stream of JSON strings (one per dataset
element) separated by newlines.</p>
<ul>
<li><em>url</em>: a <em>String</em> of the general form <code>protocol://host/path</code> or <code>/path</code>. See
  below for supported protocols</li>
<li><em>options</em>: an <em>Object</em> with the following fields:<ul>
<li><em>gzip</em>: <em>Boolean</em> (default false) to enable gzip compression. If compression
  is enabled, files are suffixed with <code>.gz</code></li>
</ul>
</li>
<li><em>done</em>: an optional callback function of the form <code>function(error, result)</code>
  called at completion. If not provided, an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</li>
</ul>
<h5 id="file-protocol">File protocol<a class="headerlink" href="#file-protocol" title="Permanent link">&para;</a></h5>
<p>The URL form is <code>file://path</code> or simply <code>path</code> where <em>path</em> is an absolute
pathname in the master host local file system.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.range(300).save('/tmp/results/').then(sc.end());
// will produce /tmp/results/0, /tmp/results/1</code></pre>


<h5 id="aws-s3-protocol">AWS S3 protocol<a class="headerlink" href="#aws-s3-protocol" title="Permanent link">&para;</a></h5>
<p>The URL form is <code>s3://bucket/key</code>. AWS credentials must be provided by environment
variables i.e <code>AWS_SECRET_ACCESS_KEY</code>, <code>AWS_ACCESS_KEY_ID</code>.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.range(300).save('s3://myproject/mydataset', {gzip: true}).then(sc.end());
// will produce https://myproject.s3.amazonaws.com/mydataset/0.gz</code></pre>


<h5 id="azure-blob-storage-protocol">Azure blob storage protocol<a class="headerlink" href="#azure-blob-storage-protocol" title="Permanent link">&para;</a></h5>
<p>The URL form is <code>wasb://container@user.blob.core.windows.net/blob_name</code>. Azure
credentials must be provided by environment variables i.e
<code>AZURE_STORAGE_ACCOUNT</code> and <code>AZURE_STORAGE_ACCESS_KEY</code>.</p>
<h4 id="dssortbykeyfunc-ascending">ds.sortBy(keyfunc[, ascending])<a class="headerlink" href="#dssortbykeyfunc-ascending" title="Permanent link">&para;</a></h4>
<p>Returns a dataset sorted by the given <em>keyfunc</em>.</p>
<ul>
<li><em>keyfunc</em>: a function of the form <code>function(element)</code> which returns
  a value used for comparison in the sort function and where <code>element</code>
  is the next element of the dataset on which <code>sortBy()</code> operates</li>
<li><em>ascending</em>: a boolean to set the sort direction. Default: true</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([4, 6, 10, 5, 1, 2, 9, 7, 3, 0])
  .sortBy(a =&gt; a)
  .collect().then(console.log)
// [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10]</code></pre>


<h4 id="dssortbykeyascending">ds.sortByKey(ascending)<a class="headerlink" href="#dssortbykeyascending" title="Permanent link">&para;</a></h4>
<p>When called on a dataset of type <code>[k,v]</code>, returns a dataset of type <code>[k,v]</code>
sorted on <code>k</code>. The optional parameter <em>ascending</em> is a boolean which sets
the sort direction, true by default.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([['world', 2], ['cedric', 3], ['hello', 1]])
  .sortByKey()
  .collect().then(console.log)
// [['cedric', 3], ['hello', 1], ['world', 2]]</code></pre>


<h4 id="dsstreamopt">ds.stream([opt])<a class="headerlink" href="#dsstreamopt" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> returns a <a href="https://nodejs.org/api/stream.html#stream_class_stream_readable">readable stream</a> of dataset content. The order
of data and partitions is maintained.</p>
<ul>
<li><em>opt</em>: an object with the following fields:</li>
<li><em>end</em>: <em>Boolean</em>, when true, call <code>sc.end()</code> on stream <code>end</code> event. Default value: false.</li>
<li><em>gzip</em>: <em>Boolean</em>, when true, enable gzip compression. Default value: false.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var s = sc.range(4).stream();
s.pipe(process.stdout);
// 0
// 1
// 2
// 3</code></pre>


<h4 id="dssubtractother">ds.subtract(other)<a class="headerlink" href="#dssubtractother" title="Permanent link">&para;</a></h4>
<p>Returns a dataset containing only elements of source dataset which
are not in <em>other</em> dataset.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([1, 2, 3, 4, 5]);
var ds2 = sc.parallelize([3, 4, 5, 6, 7]);
ds1.subtract(ds2).collect().then(console.log);
// [ 1, 2 ]</code></pre>


<h4 id="dstakenum-done">ds.take(num[, done])<a class="headerlink" href="#dstakenum-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> returns an array of the <code>num</code> first elements of the
source dataset.  The result is passed to the <em>done()</em> callback if
provided, otherwise an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>num</em>: positive integer <em>Number</em> of elements</li>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.range(5).take(2).then(console.log);
// [1, 2]</code></pre>


<h4 id="dstakesamplewithreplacement-num-done">ds.takeSample(withReplacement, num[, done])<a class="headerlink" href="#dstakesamplewithreplacement-num-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> returns an array with a random sample of <code>num</code> elements
of the dataset, with or without replacement. The result is passed to
the <em>done()</em> callback if provided, otherwise an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>withReplacement</em>: <em>Boolean</em> value, <em>true</em> if data must be sampled
  with replacement</li>
<li><em>num</em>: positive integer <em>Number</em> of elements</li>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.range(100).takeSample(4).then(console.log);
// [ 18, 75, 4, 57 ]</code></pre>


<h4 id="dstopnum-done">ds.top(num[, done])<a class="headerlink" href="#dstopnum-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> returns an array of the <code>num</code> top elements of the
source dataset.  The result is passed to the <em>done()</em> callback if
provided, otherwise an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>num</em>: positive integer <em>Number</em> of elements</li>
<li><em>done</em>: a callback of the form <code>function(error, result)</code> which is
  called at completion.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.range(5).top(2).then(console.log);
// [3, 4]</code></pre>


<h4 id="dsunionother">ds.union(other)<a class="headerlink" href="#dsunionother" title="Permanent link">&para;</a></h4>
<p>Returns a dataset that contains the union of the elements in the source
dataset and the <em>other</em> dataset.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var ds1 = sc.parallelize([1, 2, 3, 4, 5]);
var ds2 = sc.parallelize([3, 4, 5, 6, 7]);
ds1.union(ds2).collect().then(console.log);
// [ 1, 2, 3, 4, 5, 3, 4, 5, 6, 7 ]</code></pre>


<h4 id="dsvalues">ds.values()<a class="headerlink" href="#dsvalues" title="Permanent link">&para;</a></h4>
<p>When called on source dataset of type <code>[k,v]</code>, returns a dataset with just
the elements <code>v</code>.</p>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">sc.parallelize([[10, 'world'], [30, 3]]).
   keys.collect().then(console.log);
// [ 'world', 3 ]</code></pre>


<h3 id="partitioners">Partitioners<a class="headerlink" href="#partitioners" title="Permanent link">&para;</a></h3>
<p>A partitioner is an object passed to
<a href="#dspartitionbypartitioner">ds.partitionBy(partitioner)</a> which
places data in partitions according to a strategy, for example hash
partitioning, where data having the same key are placed in the same
partition, or range partitioning, where data in the same range are
in the same partition. This is useful to accelerate processing, as
it limits data transfers between workers during jobs.</p>
<p>A partition object must provide the following properties:</p>
<ul>
<li><em>numPartitions</em>: a <em>Number</em> of partitions for the dataset</li>
<li><em>getPartitionIndex</em>: a <em>Function</em> of type <code>function(element)</code>
  which returns the partition index (comprised between 0 and
  <em>numPartitions</em>) for the <code>element</code> of the dataset on which
  <code>partitionBy()</code> operates.</li>
</ul>
<h4 id="hashpartitionernumpartitions">HashPartitioner(numPartitions)<a class="headerlink" href="#hashpartitionernumpartitions" title="Permanent link">&para;</a></h4>
<p>Returns a partitioner object which implements hash based partitioning
using a hash checksum of each element as a string.</p>
<ul>
<li><em>numPartitions</em>: <em>Number</em> of partitions for this dataset</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var hp = new skale.HashPartitioner(3)
var dataset = sc.range(10).partitionBy(hp)</code></pre>


<h4 id="rangepartitionernumpartitions-keyfunc-dataset">RangePartitioner(numPartitions, keyfunc, dataset)<a class="headerlink" href="#rangepartitionernumpartitions-keyfunc-dataset" title="Permanent link">&para;</a></h4>
<p>Returns a partitioner object which first defines ranges by sampling
the dataset and then places elements by comparing them with ranges.</p>
<ul>
<li><em>numPartitions</em>: <em>Number</em> of partitions for this dataset</li>
<li><em>keyfunc</em>: a function of the form <code>function(element)</code> which returns
  a value used for comparison in the sort function and where <code>element</code>
  is the next element of the dataset on which <code>partitionBy()</code> operates</li>
<li><em>dataset</em>: the dataset object on which <code>partitionBy()</code> operates</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var dataset = sc.range(100)
var rp = new skale.RangePartitioner(3, a =&gt; a, dataset)
var dataset = sc.range(10).partitionBy(rp)</code></pre>


<h3 id="environment-variables">Environment variables<a class="headerlink" href="#environment-variables" title="Permanent link">&para;</a></h3>
<ul>
<li><code>SKALE_HOST</code>: The hostname of the skale-server process in distributed mode. If unset, the master runs in standalone mode.</li>
<li><code>SKALE_PORT</code>: The port of the skale-server process in distributed mode. Default value: "12346"</li>
<li><code>SKALE_KEY</code>: An authentication token which may be required by the skale-server process</li>
<li><code>SKALE_DEBUG</code>: set the debug trace level to the following values:</li>
<li><code>0</code>: or unset: no traces</li>
<li><code>1</code>: debug traces from master side</li>
<li><code>2</code>: above traces plus worker traces</li>
<li><code>3</code>: above traces plus network protocol traces (if running in distributed mode)</li>
</ul>
<h2 id="machine-learning-module">Machine Learning module<a class="headerlink" href="#machine-learning-module" title="Permanent link">&para;</a></h2>
<p>The Machine Learning (ML) module provides scalable functions for
supervised (classification, regression) and unsupervised (clustering)
statistical learning on top of skale datasets and distributed
map-reduce engine.</p>
<p>The module can be loaded using:</p>
<pre class="codehilite"><code class="language-javascript">var ml = require('skale-engine/ml')</code></pre>


<h3 id="mlbinaryclassificationmetricsmeasures-options-done">ml.binaryClassificationMetrics(measures, options[, done])<a class="headerlink" href="#mlbinaryclassificationmetricsmeasures-options-done" title="Permanent link">&para;</a></h3>
<h3 id="mlkmeansnbclusters-options">ml.KMeans(nbClusters[, options])<a class="headerlink" href="#mlkmeansnbclusters-options" title="Permanent link">&para;</a></h3>
<p>Creates a clusterization model fitted via <a href="https://en.wikipedia.org/wiki/K-means_clustering">K-Means</a> algorithm.</p>
<ul>
<li><em>nbClusters</em>: <em>Number</em>, specifying the number of clusters in the model</li>
<li><em>Options</em>: an optional <em>Object</em> with the following fields:</li>
<li><em>maxMse</em>: <em>Number</em> defining the maximum mean square error between cluster
    centers since previous iteration. Used to stop iterations. Default to 1e-7.</li>
<li><em>maxIterations</em>: <em>Number</em> defining the maximum number of iterations. Default: 100.</li>
<li><em>means</em>: an initial array of vectors (arrays) of numbers, default undefined.</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var dataset = sc.parallelize([
  [1, 2], [1, 4], [1, 0],
  [4, 2], [4, 4], [4, 0]
]);
kmeans = ml.KMeans(2);
await kmeans.fit(dataset);
kmeans.means
// [ [ 2.5, 1 ], [ 2.5, 4 ] ]
kmeans.predict([0, 0])
// 0
kmeans.predict([4, 4]
// 1</code></pre>


<h4 id="kmeansfittrainingset-done">kmeans.fit(trainingSet[, done])<a class="headerlink" href="#kmeansfittrainingset-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> updates <em>kmeans</em> model by fitting it to the input
dataset <em>trainingSet</em>. The result is passed to the <em>done()</em> callback
if provided, otherwise an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>trainingSet</em>: a dataset where entries are in the following format:
  <code>[feature0, feature1, ...]</code> with <em>featureN</em> being a float number.</li>
<li><em>done</em>: an optional callback of the form <code>function(error, result)</code>
  which is called at completion.</li>
</ul>
<h4 id="kmeanspredictsample">kmeans.predict(sample)<a class="headerlink" href="#kmeanspredictsample" title="Permanent link">&para;</a></h4>
<p>Returns the closest cluster index for the <em>sample</em>.</p>
<ul>
<li><em>sample</em>: an <em>Array</em> with the format <code>[feature0, feature 1, ...]</code>
  with <em>featureN</em> being a float number.</li>
</ul>
<h3 id="mlsgdlinearmodeloptions">ml.SGDLinearModel([options])<a class="headerlink" href="#mlsgdlinearmodeloptions" title="Permanent link">&para;</a></h3>
<p>Creates a regularized linear model fitted via <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic
gradient descent</a> learning. Such model can be used either for 
regression or classification, as training method is identical,
only prediction changes. SGD is sensitive to the scaling
of the features. For best results, the data should have zero mean and
unit variance, which can be achieved with <a href="#mlstandardscaler">ml.StandardScaler</a>.</p>
<p>The model it fits can be controlled with the <em>loss</em> option; by default,
it fits a linear <a href="https://en.wikipedia.org/wiki/Support_vector_machine">support vector machine</a> (SVM). A regularization term
can be added to the loss, by default the squared euclidean norm L2.</p>
<ul>
<li><em>options</em>: an <em>Object</em> with the following fields:</li>
<li><em>fitIntercept</em>: <em>Boolean</em> indicating whether to include an intercept. Default: <em>true</em></li>
<li><em>loss</em>: <em>String</em> specifying the <a href="https://en.wikipedia.org/wiki/Loss_functions_for_classification">loss function</a> to be used. Possible values are:<ul>
<li><code>hinge</code>: (default), gives a linear SVM</li>
<li><code>log</code>: gives logistic loss, a probabilistic classifier</li>
<li><code>square</code>: gives square loss fit</li>
</ul>
</li>
<li><em>penalty</em>: <em>String</em>  specifying the <a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)">regularization</a> term. Possible values are:<ul>
<li><code>l2</code>: (default) squared euclidean norm L2, standard regularizer for linear SVM models</li>
<li><code>l1</code>: absolute norm L1, might bring sparsity to the model, not achievable with <code>l2</code></li>
<li><code>none</code>: zero penalty</li>
</ul>
</li>
<li><em>proba</em>: <em>Boolean</em> (default <em>false</em>). If <em>true</em> predict returns a probability rather than a raw number. Only applicable when logisitic loss is selected.</li>
<li><em>regParam</em>: <em>Number</em>  &gt;= 0, defaults to 0.001, defines the trade-off between the
    two goals of minimizing the loss (i.e. training error) and minimizing model complexity
    (i.e. to avoid overfitting)</li>
<li><em>stepSize</em>: <em>Number</em> &gt;= 0, defaults to 1, defines the initial step size of the gradient
    descent</li>
</ul>
<p>Example:</p>
<pre class="codehilite"><code class="language-javascript">var trainingSet = sc.parallelize([
 [1, [0.5, -0.7]],
 [-1 [-0.5, 0.7]]
]);
var model = new ml.SGDLinearModel()
await model.fit(trainingSet, 2)
model.weights
// [ 0.8531998372026804, -1.1944797720837526 ]
model.predict([2, -2])
// 0.9836229103782058</code></pre>


<h4 id="sgdclassifierfittrainingset-iterations-done">sgdClassifier.fit(trainingSet, iterations[, done])<a class="headerlink" href="#sgdclassifierfittrainingset-iterations-done" title="Permanent link">&para;</a></h4>
<p>This <a href="#actions">action</a> updates <em>sgdClassifier</em> model by fitting it to the
input dataset <em>trainingSet</em>. The result is passed to the <em>done()</em>
callback if provided, otherwise an <a href="https://promisesaplus.com">ES6 promise</a> is returned.</p>
<ul>
<li><em>trainingSet</em>: a dataset where entries are in the following format:
  <code>[label, [feature0, feature1, ...]]</code> with <em>label</em> being either 1 or -1,
  and <em>featureN</em> being a float number, preferentially with a zero mean and
  unit variance (in range [-1, 1]). Sparse vectors with undefined features
  are supported.</li>
<li><em>done</em>: an optional callback of the form <code>function(error, result)</code>
  which is called at completion.</li>
</ul>
<h4 id="sgdclassifierpredictsample">sgdClassifier.predict(sample)<a class="headerlink" href="#sgdclassifierpredictsample" title="Permanent link">&para;</a></h4>
<h3 id="mlstandardscaler">ml.StandardScaler()<a class="headerlink" href="#mlstandardscaler" title="Permanent link">&para;</a></h3>
<h4 id="standardscalerfitdataset-done">standardScaler.fit(dataset, [done])<a class="headerlink" href="#standardscalerfitdataset-done" title="Permanent link">&para;</a></h4>
<h4 id="standardscalertransformfeatures">standardScaler.transform(features)<a class="headerlink" href="#standardscalertransformfeatures" title="Permanent link">&para;</a></h4>
          <aside class="copyright" role="note">
            
            Documentation built with
            <a href="http://www.mkdocs.org" target="_blank">MkDocs</a>
            using the
            <a href="http://squidfunk.github.io/mkdocs-material/" target="_blank">
              Material
            </a>
            theme.
          </aside>
          
            <footer class="footer">
              
  <nav class="pagination" aria-label="Footer">
    <div class="previous">
      
        <a href=".." title="Home">
          <span class="direction">
            Previous
          </span>
          <div class="page">
            <div class="button button-previous" role="button" aria-label="Previous">
              <i class="icon icon-back"></i>
            </div>
            <div class="stretch">
              <div class="title">
                Home
              </div>
            </div>
          </div>
        </a>
      
    </div>
    <div class="next">
      
        <a href="../skale-hackers-guide/" title="Skale hackers guide">
          <span class="direction">
            Next
          </span>
          <div class="page">
            <div class="stretch">
              <div class="title">
                Skale hackers guide
              </div>
            </div>
            <div class="button button-next" role="button" aria-label="Next">
              <i class="icon icon-forward"></i>
            </div>
          </div>
        </a>
      
    </div>
  </nav>

            </footer>
          
        </div>
      </article>
      <div class="results" role="status" aria-live="polite">
        <div class="scrollable">
          <div class="wrapper">
            <div class="meta"></div>
            <div class="list"></div>
          </div>
        </div>
      </div>
    </main>
    <script>
      var base_url = '..';
      var repo_id  = 'skale-me/skale-engine';
    </script>
    <script src="../assets/javascripts/application-997097ee0c.js"></script>
    
    
      <script>
        (function(i,s,o,g,r,a,m){
          i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){(i[r].q=i[r].q||
          []).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
          m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;
          m.parentNode.insertBefore(a,m)
        })(window, document,
          'script', 'https://www.google-analytics.com/analytics.js', 'ga');
        /* General initialization */
        ga('create', 'UA-75822605-1', 'skale-engine.github.io');
        ga('set', 'anonymizeIp', true);
        ga('send', 'pageview');
        /* Track outbound links */
        var buttons = document.querySelectorAll('a');
        Array.prototype.map.call(buttons, function(item) {
          if (item.host != document.location.host) {
            item.addEventListener('click', function() {
              var action = item.getAttribute('data-action') || 'follow';
              ga('send', 'event', 'outbound', action, item.href);
            });
          }
        });
        /* Register handler to log search on blur */
        var query = document.querySelector('.query');
        query.addEventListener('blur', function() {
          if (this.value) {
            var path = document.location.pathname;
            ga('send', 'pageview', path + '?q=' + this.value);
          }
        });
      </script>
    
  </body>
</html>